import streamlit as st
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import joblib
import os

# ----------------------- C√ÄI ƒê·∫∂T TRANG -----------------------
st.set_page_config(
    page_title="Ph√¢n t√≠ch c·∫£m x√∫c Review Phim",
    page_icon="üé¨",
    layout="centered"
)

# T·∫£i stopwords
nltk.download('stopwords', quiet=True)
stop_words = set(stopwords.words('english'))

# H√†m l√†m s·∫°ch text
def clean_text(text):
    text = re.sub(r'<.*?>', '', str(text))          # X√≥a HTML tags
    text = re.sub(r'[^a-zA-Z\s]', '', text)         # Ch·ªâ gi·ªØ ch·ªØ c√°i
    text = text.lower()
    words = [w for w in text.split() if w not in stop_words]
    return " ".join(words)

# ----------------------- CACHE M√î H√åNH -----------------------
@st.cache_resource
def load_model_and_vectorizer():
    # T·∫£i d·ªØ li·ªáu IMDB tr·ª±c ti·∫øp t·ª´ GitHub (public)
    url = "https://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv"
    df = pd.read_csv(url)
    
    # Ti·ªÅn x·ª≠ l√Ω
    df['clean_review'] = df['review'].apply(clean_text)
    df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})
    
    # Vectorizer
    vectorizer = TfidfVectorizer(
        ngram_range=(1, 2),
        min_df=2,
        max_df=0.9,
        max_features=40000,
        sublinear_tf=True,
        stop_words='english'
    )
    
    X = vectorizer.fit_transform(df['clean_review'])
    y = df['label']
    
    # Hu·∫•n luy·ªán Logistic Regression (m√¥ h√¨nh t·ªët nh·∫•t)
    model = LogisticRegression(max_iter=1000)
    model.fit(X, y)
    
    return model, vectorizer

# Load m√¥ h√¨nh (ch·ªâ ch·∫°y 1 l·∫ßn)
with st.spinner("ƒêang t·∫£i m√¥ h√¨nh... (l·∫ßn ƒë·∫ßu h∆°i l√¢u t√≠ nh√© üé•)"):
    model, vectorizer = load_model_and_vectorizer()

# ----------------------- GIAO DI·ªÜN -----------------------
st.title("üé¨ Ph√¢n t√≠ch c·∫£m x√∫c Review Phim IMDB")
st.markdown("### Nh·∫≠p review phim ƒë·ªÉ xem n√≥ **t√≠ch c·ª±c** hay **ti√™u c·ª±c** nh√©!")

user_input = st.text_area(
    "Nh·∫≠p review c·ªßa b·∫°n ·ªü ƒë√¢y:",
    height=150,
    placeholder="V√≠ d·ª•: This movie was absolutely fantastic! The acting was great and the story kept me on the edge of my seat..."
)

if st.button("D·ª± ƒëo√°n c·∫£m x√∫c", type="primary"):
    if user_input.strip() == "":
        st.warning("Vui l√≤ng nh·∫≠p m·ªôt ƒëo·∫°n review ƒë·ªÉ d·ª± ƒëo√°n!")
    else:
        with st.spinner("ƒêang ph√¢n t√≠ch..."):
            cleaned = clean_text(user_input)
            if cleaned == "":  # N·∫øu sau khi clean b·ªã r·ªóng
                st.error("Review ch·ªâ ch·ª©a k√Ω t·ª± ƒë·∫∑c bi·ªát ho·∫∑c stop words, kh√¥ng th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c.")
            else:
                vec_input = vectorizer.transform([cleaned])
                prediction = model.predict(vec_input)[0]
                probability = model.predict_proba(vec_input)[0]
                
                pos_prob = probability[1]
                neg_prob = probability[0]
                
                if prediction == 1:
                    st.success("üéâ **T√≠ch c·ª±c (Positive)**")
                    st.markdown(f"**ƒê·ªô tin c·∫≠y:** {pos_prob:.1%} t√≠ch c·ª±c ‚Äì {neg_prob:.1%} ti√™u c·ª±c")
                else:
                    st.error("üò¢ **Ti√™u c·ª±c (Negative)**")
                    st.markdown(f"**ƒê·ªô tin c·∫≠y:** {neg_prob:.1%} ti√™u c·ª±c ‚Äì {pos_prob:.1%} t√≠ch c·ª±c")
                
                # Hi·ªÉn th·ªã review ƒë√£ l√†m s·∫°ch (t√πy ch·ªçn)
                with st.expander("Xem l·∫°i review sau khi l√†m s·∫°ch"):
                    st.text(cleaned)

# Footer
st.markdown("---")
st.caption("D·ª± √°n demo s·ª≠ d·ª•ng m√¥ h√¨nh Logistic Regression hu·∫•n luy·ªán tr√™n 50.000 review IMDB ‚Äì Accuracy ~90%")
