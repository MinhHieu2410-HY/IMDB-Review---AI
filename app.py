import streamlit as st
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

# ----------------------- C√ÄI ƒê·∫∂T TRANG -----------------------
st.set_page_config(
    page_title="Ph√¢n t√≠ch c·∫£m x√∫c Review Phim",
    page_icon="üé¨",
    layout="centered"
)

# T·∫£i stopwords v√† lo·∫°i b·ªè 'not' ƒë·ªÉ gi·ªØ negation
nltk.download('stopwords', quiet=True)
stop_words = set(stopwords.words('english'))
stop_words.remove('not')  # Quan tr·ªçng: gi·ªØ "not" ƒë·ªÉ model hi·ªÉu ph·ªß ƒë·ªãnh

# H√†m l√†m s·∫°ch text - ƒê√É FIX ƒë·ªÉ x·ª≠ l√Ω t·ªët negation
def clean_text(text):
    text = re.sub(r'<.*?>', '', str(text))  # X√≥a HTML tags
    # Gi·ªØ d·∫•u nh√°y ƒë∆°n ƒë·ªÉ "don't" kh√¥ng b·ªã bi·∫øn th√†nh "dont"
    text = re.sub(r'[^a-zA-Z\s\']', '', text)
    text = text.lower()
    
    # Chu·∫©n h√≥a m·ªôt s·ªë contraction ph·ªï bi·∫øn
    text = re.sub(r"don't", "do not", text)
    text = re.sub(r"doesn't", "does not", text)
    text = re.sub(r"isn't", "is not", text)
    text = re.sub(r"aren't", "are not", text)
    text = re.sub(r"wasn't", "was not", text)
    text = re.sub(r"weren't", "were not", text)
    text = re.sub(r"haven't", "have not", text)
    text = re.sub(r"hasn't", "has not", text)
    text = re.sub(r"hadn't", "had not", text)
    text = re.sub(r"won't", "will not", text)
    text = re.sub(r"wouldn't", "would not", text)
    text = re.sub(r"can't", "cannot", text)
    text = re.sub(r"couldn't", "could not", text)
    
    words = text.split()
    words = [w for w in words if w not in stop_words]
    return " ".join(words)

# ----------------------- CACHE M√î H√åNH -----------------------
@st.cache_resource
def load_model_and_vectorizer():
    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh..."):
        # T·∫£i dataset IMDB tr·ª±c ti·∫øp t·ª´ GitHub
        url = "https://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv"
        df = pd.read_csv(url)
        
        # Ti·ªÅn x·ª≠ l√Ω
        df['clean_review'] = df['review'].apply(clean_text)
        df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})
        
        # TF-IDF Vectorizer (c·∫•u h√¨nh t·ªët nh∆∞ notebook g·ªëc)
        vectorizer = TfidfVectorizer(
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.9,
            max_features=40000,
            sublinear_tf=True,
            stop_words='english'  # v·∫´n d√πng built-in ƒë·ªÉ lo·∫°i th√™m stopwords kh√°c
        )
        
        X = vectorizer.fit_transform(df['clean_review'])
        y = df['label']
        
        # Hu·∫•n luy·ªán Logistic Regression - m√¥ h√¨nh t·ªët nh·∫•t
        model = LogisticRegression(max_iter=1000)
        model.fit(X, y)
        
    return model, vectorizer

# Load m√¥ h√¨nh
model, vectorizer = load_model_and_vectorizer()

# ----------------------- GIAO DI·ªÜN -----------------------
st.title("üé¨ Ph√¢n t√≠ch c·∫£m x√∫c Review Phim IMDB")
st.markdown("### Nh·∫≠p review phim ƒë·ªÉ bi·∫øt n√≥ **t√≠ch c·ª±c** hay **ti√™u c·ª±c**")

user_input = st.text_area(
    "Vi·∫øt review c·ªßa b·∫°n ·ªü ƒë√¢y:",
    height=150,
    placeholder="V√≠ d·ª•: I don't like this movie at all, it's boring and predictable..."
)

if st.button("D·ª± ƒëo√°n c·∫£m x√∫c", type="primary"):
    if not user_input.strip():
        st.warning("Vui l√≤ng nh·∫≠p m·ªôt ƒëo·∫°n review ƒë·ªÉ d·ª± ƒëo√°n!")
    else:
        with st.spinner("ƒêang ph√¢n t√≠ch c·∫£m x√∫c..."):
            cleaned = clean_text(user_input)
            if not cleaned.strip():
                st.error("Review sau khi x·ª≠ l√Ω b·ªã r·ªóng. H√£y th·ª≠ vi·∫øt d√†i h∆°n ho·∫∑c d√πng t·ª´ kh√°c.")
            else:
                vec_input = vectorizer.transform([cleaned])
                prediction = model.predict(vec_input)[0]
                probability = model.predict_proba(vec_input)[0]
                
                pos_prob = probability[1]
                neg_prob = probability[0]
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë·∫πp
                if prediction == 1:
                    st.success("üéâ **T√≠ch c·ª±c (Positive)**")
                    st.markdown(f"**ƒê·ªô tin c·∫≠y:** {pos_prob:.1%} t√≠ch c·ª±c ‚Äì {neg_prob:.1%} ti√™u c·ª±c")
                else:
                    st.error("üò¢ **Ti√™u c·ª±c (Negative)**")
                    st.markdown(f"**ƒê·ªô tin c·∫≠y:** {neg_prob:.1%} ti√™u c·ª±c ‚Äì {pos_prob:.1%} t√≠ch c·ª±c")
                
                # T√πy ch·ªçn: xem text ƒë√£ clean
                with st.expander("Xem review sau khi l√†m s·∫°ch (d√†nh cho dev)"):
                    st.text(cleaned)

# Footer
st.markdown("---")
st.caption("Demo s·ª≠ d·ª•ng Logistic Regression tr√™n 50.000 review IMDB ‚Ä¢ Accuracy ~90% ‚Ä¢ ƒê√£ x·ª≠ l√Ω t·ªët ph·ªß ƒë·ªãnh (don't, not, can't...)")
